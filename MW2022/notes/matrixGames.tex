In this section we discuss a special class of games - so called matrix games, which are a special case of bimatrix games. As in the first section we 
consider also here finite two player games.

\begin{definition}
    A strategic game $G = (S, \pi)$ is called a zero-sum game if $\pi_{1}(s_{1}, s_{2}) + \pi_{2}(s_{1}, s_{2}) = 0$ for every $(s_{1}, s_{2})\in S$.
\end{definition}

\begin{definition}
    Let $G = (S, \pi)$ be a zero-sum game. Then its mixed extension is called a matrix game.
\end{definition}

\begin{remark}
    Let $S_{1} = \{1, \ldots, m_{1}\}, S_{2} = \{1, \ldots, m_{2}\}$ and let $A\in\reals^{m_{1}\times m_{2}}$ defined by
    \begin{equation*}
        A = (\pi_{1}(i, j))_{1\leq i\leq m_{1}, 1\leq j\leq m_{2}}.
    \end{equation*}
    Then it holds
    \begin{equation*}
        \pi_{1}(\sigma_{1}, \sigma_{2}) = \sigma_{1}A\sigma_{2}^{T} ~~ and ~~ \pi_{1}(\sigma_{1}, \sigma_{2}) = -\sigma_{1}A\sigma_{2}^{T}
    \end{equation*}s
    for all $(\sigma_{1}, \sigma_{2})\in\Sigma$.
\end{remark}

For this special class of games we consider next to Nash equilibria another solution concept which was first introduced by John v. Neumann and is based
on the so called value of a game.

\begin{definition}
    Let $G = (S, \pi)$ be a game.
    \begin{enumerate}
        \item $v_{L} = \sup_{s_{1}\in S_{1}}\inf_{s_{2}\in S_{2}}\pi_{1}(s_{1}, s_{2})$, $v_{U} = \inf_{s_{2}\in S_{2}}\sup_{s_{1}\in S_{1}}\pi_{1}(s_{1}, s_{2})$
            are called the lower value and the upper value of $G$ respectively.
        \item If $v_{L} = v_{U}$, then the game is called strictly determined or said to have a value. In this case $v = v_{L}$ is called the value of the game.
    \end{enumerate}
\end{definition}

Let us define the mappings $\varphi:S_{1}\to\reals$, $\psi:S_{2}\to\reals$ via $\varphi(s_{1}) = \inf_{s_{2}\in S_{2}}\pi_{1}(s_{1}, s_{2})$ and 
$\psi(s_{2}) = \sup_{s_{1}\in S_{1}}\pi_{1}(s_{1}, s_{2})$. Then $\varphi(s_{1})$ refers to the worst payoff player $1$ receives if applying $s_{1}$,
and $\psi(s_{2})$ gives the maximal loss player $2$ can make when playing $s_{2}$. Thus a conservative, but suitable strategy for player $1$ may be to choose
a strategy which is maximising $\varphi$. Similarly player $2$ may seek a strategy which minimises $\psi$. 

\begin{definition}\label{def:optSol}
    Let $G = (S, \pi)$ be a game. 
    \begin{enumerate}
        \item Any $s_{1}^{*}\in S_{1}$ satisfying
            \begin{equation*}
                \varphi(s_{1}^{*}) = \sup_{s_{1}\in S_{1}}\varphi(s_{1})
            \end{equation*}
            is called a maximin strategy for player $1$.
        \item Let $s_{2}^{*}\in S_{2}$ such that
            \begin{equation*}
                \psi(s_{2}^{*}) = \inf_{s_{2}\in S_{2}}\psi(s_{2}).
            \end{equation*}
            Then $s_{2}^{*}$ is called a minimax strategy for player $2$.
    \end{enumerate}
\end{definition}

In general we cannot assume that a maximin strategy for player $1$ or a minimax strategy for player $2$ exists. Let us consider now the special case of a
matrix game. Let $A\in\reals^{m_{1}\times m_{2}}$ be the matrix corresponding to the payoff function $\pi{1}$. Due to compactness of $\Sigma_{1}$, 
$\Sigma_{2}$ and the continuity of bilinear functions we have
\begin{equation*}
    \varphi(\sigma_{1}) = \min_{\sigma_{2}\in\Sigma_{2}}\sigma_{1}A\sigma_{2}^{T} ~\text{ and }~ \psi(\sigma_{1}) = \max_{\sigma_{1}\in\Sigma_{1}}\sigma_{1}A\sigma_{2}^{T}
\end{equation*}

As the following Lemma states, the minimum in the definition of $\varphi$ and the maximum in the definition of $\psi$ is attained among the set of pure strategies.

\begin{lemma}
    For every $\sigma_{1}\in\Sigma_{1}$ and every $\sigma_{2}\in\Sigma_{2}$ it holds
    \begin{equation*}
        \varphi(\sigma_{1}) = \min_{1\leq j\leq m_{2}}\sigma_{1} Ae_{j}^{T} ~\text{ and }~ \psi(\sigma_{2}) = \max_{1\leq i\leq m_{1}}e_{i} A\sigma_{2}^{T}
    \end{equation*}
\end{lemma}
\begin{proof}
    Shouldn't be hard.
\end{proof}

According to the above statement we have in particular the following relations for the upper and lower value of the game
\begin{equation*}
    v_{L} = \max_{\sigma_{1}\in\Sigma_{1}}\min_{1\leq j\leq m_{2}}\sigma_{1} Ae_{j}^{T}, ~~ 
        v_{U} = \min_{\sigma_{2}\in\Sigma_{2}}\max_{1\leq i\leq m_{1}}e_{i} A\sigma_{2}^{T}.
\end{equation*}
Obviously it holds $v_{L}\leq v_{U}$, but it is not that obvious that also the reverse inequality holds true. This is the statement of the next theorem.

\begin{theorem}[Minimax theorem]
    Every matrix game is strictly determined.
\end{theorem}

For a proof of this theorem see for example section 2.6 in \cite{gonzalez2010introductory}. As a consequence we have that strategies $\sigma_{1}^{*}\in\Sigma_{1}$,
$\sigma_{2}^{*}\in\Sigma_{2}$ are optimal for player $1$ and player $2$ respectively in the sense of Definition \ref{def:optSol}, if 
\begin{equation*}
    \varphi(\sigma_{1}^{*}) = v = \psi(\sigma_{2}^{*}).
\end{equation*}

As the following results address, the solution concepts we were discussing, i.e. the concept of Nash equilibria and the concept of maximin and minimax solutions correlate.

\begin{proposition}
    Let $G = (S, \pi)$ be a zero-sum game, and let $(s_{1}^{*}, s_{2}^{*})\in S$ be a Nash equilibrium. Then the following statements hold true:
    \begin{enumerate}
        \item G is strictly determined 
        \item $s_{1}^{*}$ is a maximin strategy for player $1$ and $s_{2}^{*}$ is a minimax strategy for player $2$
        \item $v = u_{1}(s_{1}^{*}, s_{2}^{*})$
    \end{enumerate}
\end{proposition}

\begin{proposition}\label{prop:minimaxNash}
    Let $G = (S, \pi)$ be a zero-sum game. Let $G$ be strictly determined and let $(s_{1}^{*}$, $s_{2}^{*})\in S$ be a maximin and minimax strategy 
    for player $1$ and player $2$ respectively. Then $(s_{1}^{*}, s_{2}^{*})$ is a Nash equilibrium of $G$ and it holds $v = u_{1}(s_{1}^{*}, s_{2}^{*})$.
\end{proposition}

For the proofs of both of the statements see section 2.3 in \cite{gonzalez2010introductory}.

For matrix games it turns out that the maximin and the minimax strategies for player $1$ and player $2$ respectively can be found numerically in a 
rather convenient way\footnote{The approach presented here follows mainly \cite{lavrov}, \cite{mansour}}. Let us have again have a look on how these
 strategies are defined. The maximin strategy for player $1$ is by definition the solution of the optimisation problem
\begin{align*}
    \begin{cases}
        \max_{x\in\reals^{m_{1}}}\min_{1\leq j\leq m_{2}}xAe_{j}^{T} ~\text{ subject to}\\   
        ~~~~ x_{1} + \ldots + x_{m_{1}} = 1\\
        ~~~~ x_{1}, \ldots, x_{m_{1}}\geq 0
    \end{cases}
\end{align*}
Using a simple trick this optimisation problem can be transformed into a linear program. We note that the minimum of several terms can be 
maximised, by maximising an auxiliary variable $z$ subject to the constraint that $z$ is less or equal than every term of which the minimum is taken.
Using this approach and letting denote $\mathbf{0}, \mathbf{1}\in\reals^{m_{1}}$ the vectors whos components are equal $0$ and $1$ respectively, the
problem we aim to solve reads
\begin{align*}
    (LP_{1})
    \begin{cases}
        \max_{x\in\reals^{m_{1}}, z\in\reals}z ~\text{ subject to}\\   
        ~~~~  - xA \leq -z\mathbf{1}\\
        ~~~~ x\mathbf{1}^{T} \leq 1\\
        ~~~~ -x\mathbf{1}^{T} \leq -1\\
        ~~~~ x\geq \mathbf{0}
    \end{cases}
\end{align*}
where the inequality relations between vectors have to be understood componentwise. Similarly, for finding the minimax strategy for player $2$, we 
solve the linear program
\begin{align*}
    (LP_{2})
    \begin{cases}
        \min_{y\in\reals^{m_{2}}, z\in\reals}z ~\text{ subject to}\\   
        ~~~~ Ay^{T} \leq z\mathbf{1}\\
        ~~~~ y\mathbf{1}^{T} \leq 1\\
        ~~~~ -y\mathbf{1}^{T} \leq -1\\
        ~~~~ y\geq \mathbf{0}
    \end{cases}
\end{align*}

\begin{example}[Penalty kicks]
    Let us consider again Example \ref{ex:penalties}, which is indeed a matrix game corresponding to the matrix 
    \begin{align*}
        A = 
        \begin{bmatrix}
            0 & 2\\
            1 & 0
        \end{bmatrix}.
    \end{align*}
    We aim to find the maximin strategy for player $1$ and the minimax strategy for player $2$ by solving the linear problems $(LP_{1})$, $(LP_{2})$.
    To solve these problems we may try to find the vertices of its feasible sets and then find the largest or smallest function value among this points. For this
    purpose GeoGebra\footnote{See https://www.geogebra.org/classic?lang=en} is well suited. Alternatively we can use a numerical approach as well. Python's scipy
    package\footnote{See https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.linprog.html} provides a method for solving linear programs. The 
    code snippet for solving $(LP_{1})$ reads

    \begin{lstlisting}
        from scipy.optimize import linprog    

        # coefficient matrices and vectors of linear program
        c = [0, 0, -1]
        A_ub = [[-2, 0, 1], [0, -1, 1]]
        b_ub = [0, 0]
        A_eq = [[1, 1, 0]]            
        b_eq = [1]

        # boundaries of independent variables
        x0_bounds = (0, None)
        x1_bounds = (0, None)
        x2_bounds = (None, None)

        # solve linear program
        res = linprog(c, A_ub = A_ub, A_eq = A_eq, b_ub = b_ub,
                         b_eq = b_eq, 
                         bounds = [x0_bounds, x1_bounds, x2_bounds])
        print(res)
    \end{lstlisting}
    We obtain that the maximin strategy for player $1$ corresponds to the mixed strategy $(1 / 3, 2 / 3)$. Solving $(LP_{2})$ gives the minimax
    strategy $(2 / 3, 1 / 3)$. This results coincide with the results we obtained in Example \ref{ex:penalties} - which is not surprising according 
    to Proposition \ref{prop:minimaxNash}.
\end{example}
